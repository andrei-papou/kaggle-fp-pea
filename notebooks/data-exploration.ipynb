{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers.models.auto.tokenization_auto import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = Path('/root/data')\n",
    "FP_DATASET_DIR = DATASET_DIR / 'feedback-prize-effectiveness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 125520\n",
      "drwxrwxr-x 4 root root      4096 Jul  4 00:40 .\n",
      "drwxrwxr-x 3 root root      4096 Jul  3 18:14 ..\n",
      "-rw-rw-r-- 1 root root       306 Jun 20 09:15 sample_submission.csv\n",
      "drwxrwxr-x 2 root root      4096 Jul  3 14:14 test\n",
      "-rw-rw-r-- 1 root root      2632 Jun 20 09:15 test.csv\n",
      "drwxrwxr-x 2 root root    151552 Jul  3 14:14 train\n",
      "-rw-rw-r-- 1 root root  10908376 Jun 20 09:15 train.csv\n",
      "-rw-r--r-- 1 root root 106346745 Jul  4 00:40 train_ext.csv\n",
      "-rw-rw-r-- 1 root root  11099291 Jun 27 13:49 train_with_pos.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -la $FP_DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 18692\n",
      "drwxrwxr-x 2 root root 151552 Jul  3 14:14 .\n",
      "drwxrwxr-x 4 root root   4096 Jul  4 00:40 ..\n",
      "-rw-rw-r-- 1 root root   3590 Jun 20 09:15 00066EA9880D.txt\n",
      "-rw-rw-r-- 1 root root   1527 Jun 20 09:15 000E6DE9E817.txt\n",
      "-rw-rw-r-- 1 root root   1395 Jun 20 09:15 0016926B079C.txt\n",
      "-rw-rw-r-- 1 root root   4568 Jun 20 09:15 00203C45FC55.txt\n",
      "-rw-rw-r-- 1 root root   1551 Jun 20 09:15 0029F4D19C3F.txt\n",
      "-rw-rw-r-- 1 root root   1090 Jun 20 09:15 0045BE2791A2.txt\n",
      "-rw-rw-r-- 1 root root   1846 Jun 20 09:15 004AC288D833.txt\n",
      "ls: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!ls -la $FP_DATASET_DIR/train | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(FP_DATASET_DIR / 'train_with_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>discourse_text_token_len</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36760</th>\n",
       "      <td>9f63b687e76a</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>For many people they don't like only asking on...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36761</th>\n",
       "      <td>9d5bd7d86212</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>also people have different views and opinions ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36762</th>\n",
       "      <td>f1b78becd573</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>Advice is something that can impact a persons ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36763</th>\n",
       "      <td>cc184624ca8e</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>someone can use everything that many people sa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36764</th>\n",
       "      <td>c8a973681feb</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>In conclusion asking for an opinion can be ben...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36765 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       discourse_id      essay_id  \\\n",
       "0      0013cc385424  007ACE74B050   \n",
       "1      9704a709b505  007ACE74B050   \n",
       "2      c22adee811b6  007ACE74B050   \n",
       "3      a10d361e54e4  007ACE74B050   \n",
       "4      db3e453ec4e2  007ACE74B050   \n",
       "...             ...           ...   \n",
       "36760  9f63b687e76a  FFA381E58FC6   \n",
       "36761  9d5bd7d86212  FFA381E58FC6   \n",
       "36762  f1b78becd573  FFA381E58FC6   \n",
       "36763  cc184624ca8e  FFA381E58FC6   \n",
       "36764  c8a973681feb  FFA381E58FC6   \n",
       "\n",
       "                                          discourse_text  \\\n",
       "0      Hi, i'm Isaac, i'm going to be writing about h...   \n",
       "1      On my perspective, I think that the face is a ...   \n",
       "2      I think that the face is a natural landform be...   \n",
       "3      If life was on Mars, we would know by now. The...   \n",
       "4      People thought that the face was formed by ali...   \n",
       "...                                                  ...   \n",
       "36760  For many people they don't like only asking on...   \n",
       "36761  also people have different views and opinions ...   \n",
       "36762  Advice is something that can impact a persons ...   \n",
       "36763  someone can use everything that many people sa...   \n",
       "36764  In conclusion asking for an opinion can be ben...   \n",
       "\n",
       "             discourse_type discourse_effectiveness  discourse_text_token_len  \\\n",
       "0                      Lead                Adequate                        84   \n",
       "1                  Position                Adequate                        50   \n",
       "2                     Claim                Adequate                        25   \n",
       "3                  Evidence                Adequate                        93   \n",
       "4              Counterclaim                Adequate                        23   \n",
       "...                     ...                     ...                       ...   \n",
       "36760                 Claim                Adequate                        25   \n",
       "36761                 Claim                Adequate                        12   \n",
       "36762              Position                Adequate                        27   \n",
       "36763              Evidence             Ineffective                        93   \n",
       "36764  Concluding Statement             Ineffective                        14   \n",
       "\n",
       "       pos  \n",
       "0        0  \n",
       "1        1  \n",
       "2        2  \n",
       "3        3  \n",
       "4        4  \n",
       "...    ...  \n",
       "36760    0  \n",
       "36761    1  \n",
       "36762    2  \n",
       "36763    3  \n",
       "36764    4  \n",
       "\n",
       "[36765 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499edab7c60e4634b416a96cc00b62ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _get_essay_text(essay_id: str) -> str:\n",
    "    with open(FP_DATASET_DIR / f'train/{essay_id}.txt') as f:\n",
    "        return f.read().strip()\n",
    "\n",
    "train_df['essay_text'] = train_df['essay_id'].progress_apply(_get_essay_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/root/.virtualenvs/feedback-prize/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class _TokInputV1Getter:\n",
    "\n",
    "#     def __init__(self, df: pd.DataFrame, tokenizer: AutoTokenizer):\n",
    "#         self._df = df\n",
    "#         self._tokenizer = tokenizer\n",
    "\n",
    "#     def __call__(self, row: t.Dict[str, t.Any]) -> str:\n",
    "#         (\n",
    "#             id,\n",
    "#             disc_type,\n",
    "#             text,\n",
    "#             target,\n",
    "#             essay_id,\n",
    "#             essay_text,\n",
    "#          ) = (\n",
    "#             str(row['discourse_id']),\n",
    "#             str(row['discourse_type']),\n",
    "#             str(row['discourse_text']),\n",
    "#             str(row['discourse_effectiveness']),\n",
    "#             str(row['essay_id']),\n",
    "#             str(row['essay_text']),\n",
    "#          )\n",
    "#         sep = self._tokenizer.sep_token\n",
    "#         other_disc_str = ', '.join([\n",
    "#             row['discourse_type']\n",
    "#             for _, row in self._df[self._df['essay_id'] == essay_id].sort_values('pos').iterrows()\n",
    "#         ])\n",
    "#         return f'{disc_type} {sep} {other_disc_str} {sep} {text}'\n",
    "\n",
    "\n",
    "# _tok_input_v1_getter = _TokInputV1Getter(train_df, tokenizer)\n",
    "# train_df['tokenizer_input_v1'] = train_df.progress_apply(_tok_input_v1_getter, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TokInputV2Getter:\n",
    "    _DISC_TYPE_SEP = '[TYPE]'\n",
    "    _DISC_PAIR_SEP = '[PAIR]'\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: AutoTokenizer):\n",
    "        self._df = df\n",
    "        self._tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, row: t.Dict[str, t.Any]) -> str:\n",
    "        (\n",
    "            id,\n",
    "            disc_type,\n",
    "            text,\n",
    "            target,\n",
    "            essay_id,\n",
    "            essay_text,\n",
    "         ) = (\n",
    "            str(row['discourse_id']),\n",
    "            str(row['discourse_type']),\n",
    "            str(row['discourse_text']),\n",
    "            str(row['discourse_effectiveness']),\n",
    "            str(row['essay_id']),\n",
    "            str(row['essay_text']),\n",
    "         )\n",
    "        sep = self._tokenizer.sep_token\n",
    "        this_disc_str = f'{disc_type} {self._DISC_TYPE_SEP} {text}'\n",
    "        other_disc_str = f' {self._DISC_PAIR_SEP} '.join([\n",
    "            str(row['discourse_type']) + f' {self._DISC_TYPE_SEP} ' + str(row['discourse_text'])\n",
    "            for _, row in self._df[self._df['essay_id'] == essay_id].sort_values('pos').iterrows()\n",
    "        ])\n",
    "        return f'{this_disc_str} {sep} {other_disc_str}'\n",
    "\n",
    "\n",
    "_tok_input_v2_getter = _TokInputV2Getter(train_df, tokenizer)\n",
    "# train_df['tokenizer_input_v2'] = train_df.progress_apply(_tok_input_v2_getter, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TokInputV3Getter:\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: AutoTokenizer, convert_to_lowercase: bool = False):\n",
    "        self._df = df\n",
    "        self._tokenizer = tokenizer\n",
    "        self._convert_to_lowercase = convert_to_lowercase\n",
    "\n",
    "    def __call__(self, row: t.Dict[str, t.Any]) -> str:\n",
    "        (\n",
    "            id,\n",
    "            disc_type,\n",
    "            text,\n",
    "            target,\n",
    "            essay_id,\n",
    "         ) = (\n",
    "            str(row['discourse_id']),\n",
    "            str(row['discourse_type']),\n",
    "            str(row['discourse_text']),\n",
    "            str(row['discourse_effectiveness']),\n",
    "            str(row['essay_id']),\n",
    "         )\n",
    "        sep = self._tokenizer.sep_token\n",
    "        essay_text = f'\\n'.join([\n",
    "            str(row['discourse_text'])\n",
    "            for _, row in self._df[(self._df['essay_id'] == essay_id) & (self._df['discourse_id'] != id)].sort_values('pos').iterrows()\n",
    "        ])\n",
    "        result = f'{disc_type} {sep} {text} {sep} {essay_text}'\n",
    "        if self._convert_to_lowercase:\n",
    "            result = result.lower()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tokenizer_input_v3'] = train_df.progress_apply(_TokInputV3Getter(train_df, tokenizer), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ce31b6afaf4cd0995a5d885686ff23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['tokenizer_input_v3_lower'] = train_df.progress_apply(_TokInputV3Getter(train_df, tokenizer, convert_to_lowercase=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43ee96905ed4a9d8d5289febea144ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7670d1951265461b8923173e4933b5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class _TokLenGetter:\n",
    "\n",
    "    def __init__(self, tokenizer: AutoTokenizer):\n",
    "        self._tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, text: str) -> int:\n",
    "        return len(self._tokenizer(text)['input_ids'])\n",
    "\n",
    "\n",
    "_tok_len_getter = _TokLenGetter(tokenizer)\n",
    "\n",
    "# train_df['discourse_text_len'] = train_df['discourse_text'].progress_apply(_tok_len_getter)\n",
    "# train_df['essay_text_len'] = train_df['essay_text'].progress_apply(_tok_len_getter)\n",
    "# train_df['tokenizer_input_v2_len'] = train_df['tokenizer_input_v2'].progress_apply(_tok_len_getter)\n",
    "train_df['tokenizer_input_v3_len'] = train_df['tokenizer_input_v3'].progress_apply(_tok_len_getter)\n",
    "train_df['tokenizer_input_v3_lower_len'] = train_df['tokenizer_input_v3_lower'].progress_apply(_tok_len_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36765.000000\n",
       "mean       505.793635\n",
       "std        243.457717\n",
       "min         32.000000\n",
       "25%        319.000000\n",
       "50%        449.000000\n",
       "75%        640.000000\n",
       "max       1597.000000\n",
       "Name: tokenizer_input_v3_len, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['tokenizer_input_v3_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36765.000000\n",
       "mean       510.538964\n",
       "std        243.705613\n",
       "min         36.000000\n",
       "25%        324.000000\n",
       "50%        454.000000\n",
       "75%        646.000000\n",
       "max       1605.000000\n",
       "Name: tokenizer_input_v3_lower_len, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['tokenizer_input_v3_lower_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046130830953352374"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df[train_df['tokenizer_input_v3_len'] > 1024]) / len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>discourse_text_token_len</th>\n",
       "      <th>pos</th>\n",
       "      <th>essay_text</th>\n",
       "      <th>tokenizer_input_v2</th>\n",
       "      <th>tokenizer_input_v2_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead [TYPE] Hi, i'm Isaac, i'm going to be wri...</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Position [TYPE] On my perspective, I think tha...</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Claim [TYPE] I think that the face is a natura...</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Evidence [TYPE] If life was on Mars, we would ...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Counterclaim [TYPE] People thought that the fa...</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36760</th>\n",
       "      <td>9f63b687e76a</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>For many people they don't like only asking on...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Some people may ask multiple people for advice...</td>\n",
       "      <td>Claim [TYPE] For many people they don't like o...</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36761</th>\n",
       "      <td>9d5bd7d86212</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>also people have different views and opinions ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Some people may ask multiple people for advice...</td>\n",
       "      <td>Claim [TYPE] also people have different views ...</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36762</th>\n",
       "      <td>f1b78becd573</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>Advice is something that can impact a persons ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>Some people may ask multiple people for advice...</td>\n",
       "      <td>Position [TYPE] Advice is something that can i...</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36763</th>\n",
       "      <td>cc184624ca8e</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>someone can use everything that many people sa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>Some people may ask multiple people for advice...</td>\n",
       "      <td>Evidence [TYPE] someone can use everything tha...</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36764</th>\n",
       "      <td>c8a973681feb</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>In conclusion asking for an opinion can be ben...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>Some people may ask multiple people for advice...</td>\n",
       "      <td>Concluding Statement [TYPE] In conclusion aski...</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36765 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       discourse_id      essay_id  \\\n",
       "0      0013cc385424  007ACE74B050   \n",
       "1      9704a709b505  007ACE74B050   \n",
       "2      c22adee811b6  007ACE74B050   \n",
       "3      a10d361e54e4  007ACE74B050   \n",
       "4      db3e453ec4e2  007ACE74B050   \n",
       "...             ...           ...   \n",
       "36760  9f63b687e76a  FFA381E58FC6   \n",
       "36761  9d5bd7d86212  FFA381E58FC6   \n",
       "36762  f1b78becd573  FFA381E58FC6   \n",
       "36763  cc184624ca8e  FFA381E58FC6   \n",
       "36764  c8a973681feb  FFA381E58FC6   \n",
       "\n",
       "                                          discourse_text  \\\n",
       "0      Hi, i'm Isaac, i'm going to be writing about h...   \n",
       "1      On my perspective, I think that the face is a ...   \n",
       "2      I think that the face is a natural landform be...   \n",
       "3      If life was on Mars, we would know by now. The...   \n",
       "4      People thought that the face was formed by ali...   \n",
       "...                                                  ...   \n",
       "36760  For many people they don't like only asking on...   \n",
       "36761  also people have different views and opinions ...   \n",
       "36762  Advice is something that can impact a persons ...   \n",
       "36763  someone can use everything that many people sa...   \n",
       "36764  In conclusion asking for an opinion can be ben...   \n",
       "\n",
       "             discourse_type discourse_effectiveness  discourse_text_token_len  \\\n",
       "0                      Lead                Adequate                        84   \n",
       "1                  Position                Adequate                        50   \n",
       "2                     Claim                Adequate                        25   \n",
       "3                  Evidence                Adequate                        93   \n",
       "4              Counterclaim                Adequate                        23   \n",
       "...                     ...                     ...                       ...   \n",
       "36760                 Claim                Adequate                        25   \n",
       "36761                 Claim                Adequate                        12   \n",
       "36762              Position                Adequate                        27   \n",
       "36763              Evidence             Ineffective                        93   \n",
       "36764  Concluding Statement             Ineffective                        14   \n",
       "\n",
       "       pos                                         essay_text  \\\n",
       "0        0  Hi, i'm Isaac, i'm going to be writing about h...   \n",
       "1        1  Hi, i'm Isaac, i'm going to be writing about h...   \n",
       "2        2  Hi, i'm Isaac, i'm going to be writing about h...   \n",
       "3        3  Hi, i'm Isaac, i'm going to be writing about h...   \n",
       "4        4  Hi, i'm Isaac, i'm going to be writing about h...   \n",
       "...    ...                                                ...   \n",
       "36760    0  Some people may ask multiple people for advice...   \n",
       "36761    1  Some people may ask multiple people for advice...   \n",
       "36762    2  Some people may ask multiple people for advice...   \n",
       "36763    3  Some people may ask multiple people for advice...   \n",
       "36764    4  Some people may ask multiple people for advice...   \n",
       "\n",
       "                                      tokenizer_input_v2  \\\n",
       "0      Lead [TYPE] Hi, i'm Isaac, i'm going to be wri...   \n",
       "1      Position [TYPE] On my perspective, I think tha...   \n",
       "2      Claim [TYPE] I think that the face is a natura...   \n",
       "3      Evidence [TYPE] If life was on Mars, we would ...   \n",
       "4      Counterclaim [TYPE] People thought that the fa...   \n",
       "...                                                  ...   \n",
       "36760  Claim [TYPE] For many people they don't like o...   \n",
       "36761  Claim [TYPE] also people have different views ...   \n",
       "36762  Position [TYPE] Advice is something that can i...   \n",
       "36763  Evidence [TYPE] someone can use everything tha...   \n",
       "36764  Concluding Statement [TYPE] In conclusion aski...   \n",
       "\n",
       "       tokenizer_input_v2_len  \n",
       "0                         591  \n",
       "1                         557  \n",
       "2                         532  \n",
       "3                         600  \n",
       "4                         531  \n",
       "...                       ...  \n",
       "36760                     228  \n",
       "36761                     215  \n",
       "36762                     230  \n",
       "36763                     296  \n",
       "36764                     218  \n",
       "\n",
       "[36765 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('feedback-prize')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4bdb910d5a1d13cf3dadcf35b3d85c5b41073a46648bc4fa6100093e0e32196"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
